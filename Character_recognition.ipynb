{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Character_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhantomHunt/Major-Project/blob/master/Character_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eBVbjRVe3Lof"
      },
      "source": [
        "## Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6b75lRZUw16",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GRoMwNng6cvU"
      },
      "source": [
        "Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYadXG886hY-",
        "outputId": "c3e68830-321c-4aa6-9489-fa80518094f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "# !pip uninstall -y tensorflow\n",
        "!pip install tensorflow\n",
        "#!pip install tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import datetime\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zR7g_efY6wBh",
        "outputId": "95a562e6-7329-49cc-e049-7b54f4a58158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "#converting 3D tensor to 2D tensor\n",
        "print (\"Before reshaping\")\n",
        "print (\"================\")\n",
        "print (\"Number of axes in train_images: \", train_images.ndim)\n",
        "print (\"Number of axes in test_images: \", test_images.ndim)\n",
        "print (\"Shape of train_images: \", train_images.shape)\n",
        "print (\"Shape of test_images: \", test_images.shape)\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "print (\"\\nAfter reshaping:\")\n",
        "print (\"================\")\n",
        "print (\"Number of axes in train_images: \", train_images.ndim)\n",
        "print (\"Number of axes in test_images: \", test_images.ndim)\n",
        "print (\"Shape of train_images: \", train_images.shape)\n",
        "print (\"Shape of test_images: \", test_images.shape)\n",
        "print ()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Before reshaping\n",
            "================\n",
            "Number of axes in train_images:  3\n",
            "Number of axes in test_images:  3\n",
            "Shape of train_images:  (60000, 28, 28)\n",
            "Shape of test_images:  (10000, 28, 28)\n",
            "\n",
            "After reshaping:\n",
            "================\n",
            "Number of axes in train_images:  4\n",
            "Number of axes in test_images:  4\n",
            "Shape of train_images:  (60000, 28, 28, 1)\n",
            "Shape of test_images:  (10000, 28, 28, 1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BAwhGbkf8H-Q"
      },
      "source": [
        "### Create the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nN8T1dOR-bM7",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTf1QRLF-fQM"
      },
      "source": [
        "The 6 lines of code below define the convolutional base using a common pattern: a stack of Conv2D and MaxPooling2D layers.\n",
        "\n",
        "As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b1FHaD0S_L3S",
        "colab": {}
      },
      "source": [
        "model.add(layers.Conv2D(32, (3,3,), activation='relu', input_shape=(28, 28, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qxgrtwdX_VQW",
        "colab": {}
      },
      "source": [
        "model.add(layers.MaxPooling2D((2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TdLX8D4o_drz",
        "colab": {}
      },
      "source": [
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RaHsqobx_-EO",
        "colab": {}
      },
      "source": [
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "grOANO1hAH9w",
        "outputId": "4515152f-2808-474c-9c5e-01d3a3937cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()\n",
        "#we did not use padding. for 2nd and 3rd convolution op, we used 64 filters each and in first used 32 filters. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YARxPpg3AKEc"
      },
      "source": [
        "To complete our model, we will feed the last output tensor from the convolutional base (of shape(3, 3, 64)) into one or more Dense layers to perform classification. Dense layers take vectors as input (which are 1D), while the current output in a 3D tensor. First, we will fatten (or unroll) the 3D output to 1D, then add one or more Dense layers on top. MNIST has 10 output classes, so we use final Dense layer with 10 ouputs and a softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rf6--5aNA7Pq",
        "colab": {}
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LNVZfy3cBFMc",
        "outputId": "ae948083-599d-4a8b-d655-8135e4d1b255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nRdlBQBkBI6t"
      },
      "source": [
        "Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RM8s6VTuBn-y",
        "outputId": "ff52b93c-4e44-473f-8167-0d48c1e805f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1364 - accuracy: 0.9569\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0442 - accuracy: 0.9858\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0317 - accuracy: 0.9901\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0255 - accuracy: 0.9917\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0193 - accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e801d82e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9T3v0uY5B2B8"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OShqm9gGB-sQ",
        "outputId": "c35ede43-618e-49ed-fb9d-8cd1800c3e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print (test_acc*100, '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0452 - accuracy: 0.9874\n",
            "98.73999953269958 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G0A0ikraIQJG"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZTkKuAhyEyQK",
        "outputId": "b8669ced-168a-4b2e-d727-7f14e675fc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FHjNsWGEEyKb",
        "outputId": "8f311159-5731-4676-be4d-5cbb89c791d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "  return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "img = mpimg.imread('/content/drive/My Drive/Colab Notebooks/8.jpeg')\n",
        "gray = rgb2gray(img)\n",
        "plt.imshow(gray, cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sf3P3e_-Ex_j",
        "outputId": "0cff8880-d519-4cee-f718-77d3ba807001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gray.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "01Rge6HgGatL",
        "outputId": "dc109cfb-4e6a-481d-edc0-d8112daec84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_img = np.expand_dims(gray, axis=2)\n",
        "new_img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QDw13LPZGafm",
        "outputId": "7db4e680-2329-42ee-82dc-db61f0be88c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "test_predict = model.predict([[new_img]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b8e5cc27a5d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1269\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 2706\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1150 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1125 predict_step  **\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 28, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SKkaTEaBGaZ6",
        "colab": {}
      },
      "source": [
        "test_predict\n",
        "max=0\n",
        "for i in test_predict:\n",
        "  if(test_predict[i]>max):\n",
        "    max=test_predict[i]\n",
        "\n",
        "print(\"The Number is \",max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "seN--xdqCFiy"
      },
      "source": [
        "## Classification with Feedforward Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2npSGg2CWfn",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQ6rU5vXCieY",
        "colab": {}
      },
      "source": [
        "model_dnn = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_dnn.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KkW0rwTUDDWP",
        "outputId": "8ae0c08d-5b45-4446-eea3-927a0b31cad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model_dnn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scY0CDgyDHjH",
        "outputId": "64b8d7f5-1a73-494f-ac5c-b23bcbf082cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model_dnn.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2990 - accuracy: 0.9124\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1412 - accuracy: 0.9584\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1062 - accuracy: 0.9675\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0859 - accuracy: 0.9737\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0750 - accuracy: 0.9762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90ba2d98d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D-T1qkSEDOih",
        "outputId": "6eaf72cd-7377-47e4-f38c-9c697007e243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_loss, test_acc = model_dnn.evaluate(x_test, y_test)\n",
        "print (test_acc*100, '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 66us/sample - loss: 0.0799 - accuracy: 0.9750\n",
            "97.50000238418579 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XnWsCCi_EPpv",
        "outputId": "62f3fbc2-5d0e-4bd5-e1d1-745f9556eedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "  return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "img = mpimg.imread('/content/drive/My Drive/Colab Notebooks/8.jpeg')\n",
        "gray = rgb2gray(img)\n",
        "plt.imshow(gray, cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARwElEQVR4nO3dbYyV5ZkH8P+fl1EQBAYGHIEstfpBs7q0TsiaksqmWUQTBeJLikmDkSyNUdOamqjsh+IXY8y2TWM2TehCgE2XpklL5IPp1iUkpl8aRjPLi7jVIgg4zgAjw/A+w1z7YR7MiPNc9/G5z3Oeg/f/l5CZOdc857nnnPPnzJzr3PdNM4OIfP2Nq3oAItIYCrtIIhR2kUQo7CKJUNhFEjGhkSebNWuWLViwoJGn/FyVXQeSbn14eDjq+seNK/5/dtnnjr1++TLvsfzxxx/j5MmTYz7gosJOchmAXwIYD+A/zOxV7/sXLFiA3bt3x5yysMuXL5d2fCjMLS0tbv38+fOFxnTFpEmTCh9b9rnPnTsXdf0xQvdLjNCTR5n/yXmPxSVLluTWCj8lkBwP4N8B3A/gDgCrSN5R9PpEpFwxf7MvAvChmR00s0sAfgtgeX2GJSL1FhP2uQCOjPr6aHbZF5BcS7KTZOfx48cjTiciMUp/Nd7MNphZh5l1tLW1lX06EckRE/ZjAOaP+npedpmINKGYsO8GcBvJb5BsAfB9ADvqMywRqbfCrTczGyL5DID/xkjrbZOZ7Q8cg0uXLhU9ZdMKtfVC7a3Q8ePHj3frFy9ezK2FWkCh+yN07jLvz9h2aUzrLfRzh667qse51xKM6rOb2ZsA3oy5DhFpDL1dViQRCrtIIhR2kUQo7CKJUNhFEqGwiySiofPZq+yzh/qmMWJ7rrFjGxwczK15PXgg3IcPTc8N/Wwx6wiE+uxlTmGNfe9DmYaGhgodp2d2kUQo7CKJUNhFEqGwiyRCYRdJhMIukoiGt95ipy1ei8pu43jXH3vuUJsn1FqLaY/FrtDq/exl3ua1iGlJFh27ntlFEqGwiyRCYRdJhMIukgiFXSQRCrtIIhR2kUQ0tM9epdi+aExfNtRTDY0ttl6m0BTXCROKP8RCP1fRqZ61HBsad5lbgMfcn9649MwukgiFXSQRCrtIIhR2kUQo7CKJUNhFEqGwiyRC89lrFDM3OtTTjekXh1S9tXCV93fMuat8X0ZZosJO8hCAAQCXAQyZWUc9BiUi9VePZ/Z/MrMTdbgeESmR/mYXSURs2A3An0i+Q3LtWN9Aci3JTpKdJ0+ejDydiBQVG/bFZvZtAPcDeJrkd6/+BjPbYGYdZtYxc+bMyNOJSFFRYTezY9nHXgDbASyqx6BEpP4Kh53kDSSnXvkcwFIA++o1MBGpr5hX4+cA2J71cScA+C8z+2PMYGL6zddq/x4ot6cbWns99tzXXXedWw9tGe2pslcde7uU+Xj0bhdvPnvhsJvZQQD/UPR4EWkstd5EEqGwiyRCYRdJhMIukgiFXSQRDZ/iWlZ7rexWSZltoNixxyzXHJriOm6c/3wwadIkt+7d36Fxl3mflN2qjWk5xvBarXpmF0mEwi6SCIVdJBEKu0giFHaRRCjsIolQ2EUS0dA++/DwMM6cOZNbD/VNq+yrxiwlHRI6PjSN9Pnnn8+thd7XcODAAbfe1dXl1tevX+/WH3744dxae3u7e2xvb69bnzp1qluPeV9G2fdpjKKPZT2ziyRCYRdJhMIukgiFXSQRCrtIIhR2kUQo7CKJaGifnWRlywNXuSxx6NyhOeVPPPGEW3/ttddya62tre6xZ8+edeu33HKLW1++fLlbnzt3bm7tvvvuc48N3W6nTp1y6977E1paWtxjQ+9PCPW6m3Fpcz2ziyRCYRdJhMIukgiFXSQRCrtIIhR2kUQo7CKJaPi68TH9x6q2wY09d6iPvmfPHre+YsUKt37zzTfn1kJzwqdPn+7Wt23b5tZfeeUVt75z587cWn9/v3tsqBces1106P4MrZcfuk+r4m3ZHHxmJ7mJZC/JfaMuayX5FskPso8z6jRWESlJLb/Gbwaw7KrLXgSw08xuA7Az+1pEmlgw7Gb2NoC+qy5eDmBL9vkWAP7vmSJSuaIv0M0xs+7s808BzMn7RpJrSXaS7Ozru/r/DBFplOhX423kFYHcVwXMbIOZdZhZR2hShoiUp2jYe0i2A0D20X/JV0QqVzTsOwCszj5fDeCN+gxHRMoS7LOT3AZgCYBZJI8C+CmAVwH8juQaAIcBPFbLyUJ99mu1jx46dvbs2W69ra3Nrb/++utu/cknn8ytffLJJ+6xhw8fduuLFi1y66H92Xt6enJrZa/d7u3/Hrt/eug9ACQLX3doLn1RwbCb2aqc0vfqPBYRKZHeLiuSCIVdJBEKu0giFHaRRCjsIolo6BTXWDHbJpfd5vGEppnefvvtbv2hhx5y63feeWdubdeuXe6xobZgaLnm/fv3u3Xvdp88eXLhYwFgYGDArXtTYGOX9449vgp6ZhdJhMIukgiFXSQRCrtIIhR2kUQo7CKJUNhFEtHwpaRj+o8x02PLnOIaEru97+rVq936XXfdlVu755573GNvvfVWt75s2dVrjX5RaIrss88+69Y9oT56aBns06dP59ZCS0VPmTKl8HUD4SmwnpjHYtRS0iLy9aCwiyRCYRdJhMIukgiFXSQRCrtIIhR2kUQ0fD57TA8xZondspbnBfwli4Fwz7W7u9uth3rC8+bNy629//777rHPPfecW9+8ebNbnzZtmls/c+ZMbi30WBgcHHTrVfWygfj57lXQM7tIIhR2kUQo7CKJUNhFEqGwiyRCYRdJhMIukohrat14r59dZh89dO5QT/X8+fNuPbTtccwa5Xfffbd7bGg76HXr1hU+NwAsXrw4t7Z161b32JtuusmtHzx40K3PmDEjtzZx4kT32NBa/zfeeKNbL3N9hKKCz+wkN5HsJblv1GXrSR4j2ZX9e6DcYYpIrFp+jd8MYKzlSn5hZguzf2/Wd1giUm/BsJvZ2wD6GjAWESlRzAt0z5Dck/2an/vHEcm1JDtJdn722WcRpxORGEXD/isA3wSwEEA3gJ/lfaOZbTCzDjPr8F4wEZFyFQq7mfWY2WUzGwbwawCL6jssEam3QmEn2T7qy5UA9uV9r4g0h2CfneQ2AEsAzCJ5FMBPASwhuRCAATgE4Ie1nMzMMDw8XHiwMcfG8vr4oR5/aL77uXPn3Lq3zzgAvPzyy7m1UC871OMP9ZtD66t3dXXl1u6991732B07drj166+/3q1794u3vnotQu8vCF2/Vw/16EkWut5g2M1s1RgXbwwdJyLNRW+XFUmEwi6SCIVdJBEKu0giFHaRRDR8y+ay2iGxUwrLXPo3NMW1vb3drYe2PX700Udza62tre6xoS2XJ0+e7Nb7+vxpE95S0i+99JJ77MaNftNn5cqVbt17TITu79AU2AsXLrj1ULs1pvVW9Hr1zC6SCIVdJBEKu0giFHaRRCjsIolQ2EUSobCLJOKa2rK5rN5k2aZOnerWQ9MlP/roI7fe1taWWwv1+EN99ND025kzZ7p17/wLFy50j+3s7HTroe2iT5w4kVs7deqUe2zo5zp79qxbL5P3WFefXUQUdpFUKOwiiVDYRRKhsIskQmEXSYTCLpKIptqyuextl6ty5MgRtz579my3/sgjj7j148eP59ZCc+UvXrzo1kPvEQj1q2OuO7Ql88DAgFv35qyHlucOvfehpaXFrZfJ+7m8Zab1zC6SCIVdJBEKu0giFHaRRCjsIolQ2EUSobCLJKKp1o2vUsx8+NAa5KE+esjjjz/u1l944YXc2t69e91jly5d6tZj+809PT25tS1btrjHPvjgg2499B6BWbNm5dYOHTrkHht6nIbWAQgdX9b6C1Hz2UnOJ7mL5Hsk95P8UXZ5K8m3SH6QfZxRxzGLSJ3V8mv8EICfmNkdAP4RwNMk7wDwIoCdZnYbgJ3Z1yLSpIJhN7NuM3s3+3wAwAEAcwEsB3Dl97AtAFaUNUgRifeVXqAjuQDAtwD8BcAcM+vOSp8CmJNzzFqSnSQ7Y95HLSJxag47ySkAfg/gx2Z2enTNRl4VGPOVATPbYGYdZtYxffr0qMGKSHE1hZ3kRIwE/Tdm9ofs4h6S7Vm9HUBvOUMUkXoItt44MmduI4ADZvbzUaUdAFYDeDX7+EYtJxweHs6tVdmWq3LL5tC5+/v73bq39fHJkyfdY7dv3+7WQ623UAvJ+9meeuop99jQFFhvai8AHD16NLcWWio6tIS2t0w1EG7NxSi6lHQtffbvAPgBgL0ku7LL1mEk5L8juQbAYQCP1TpYEWm8YNjN7M8A8mbEf6++wxGRsujtsiKJUNhFEqGwiyRCYRdJhMIukoiGT3H1eoRlbrsc6mWXee7QdU+aNMmtxyxbPGGCfxevWbOm8HUDcX32CxcuuMd6yyLXYuLEibm10PsPQrd56N2gofdWVEHP7CKJUNhFEqGwiyRCYRdJhMIukgiFXSQRCrtIIpqqzx7bV/XE9INjrzvUR+/u7nbroW2XvTnnoXOHhOazh243b/2CceP855q+vj633tbW5ta9ZdBCffRQPXaNgrJoy2YRUdhFUqGwiyRCYRdJhMIukgiFXSQRCrtIIhraZwf8da3LFOrhe/3gWIODg259xgx/A9zQvO8YZ8+ejTo+9LPF8OajA34fHYhboyD2/QVVrY8QtWWziHw9KOwiiVDYRRKhsIskQmEXSYTCLpIIhV0kEbXszz4fwFYAcwAYgA1m9kuS6wH8C4Arm2SvM7M3Q9dX1Xz2kCr7plUqe9710NBQqddfltj7uxkfL7W8qWYIwE/M7F2SUwG8Q/KtrPYLM/u38oYnIvVSy/7s3QC6s88HSB4AMLfsgYlIfX2lv9lJLgDwLQB/yS56huQekptIjvmeT5JrSXaS7Ozv748arIgUV3PYSU4B8HsAPzaz0wB+BeCbABZi5Jn/Z2MdZ2YbzKzDzDqmTZtWhyGLSBE1hZ3kRIwE/Tdm9gcAMLMeM7tsZsMAfg1gUXnDFJFYwbBz5CXyjQAOmNnPR10+esnTlQD21X94IlIvtbwa/x0APwCwl2RXdtk6AKtILsRIO+4QgB+GrsjM3FZMaGlhr51RdgupGVsptbiWW4rNPLZrUS2vxv8ZwFgN8GBPXUSah95BJ5IIhV0kEQq7SCIUdpFEKOwiiVDYRRLR8C2bvSWbQ8s5e1NgY7dkrmrpX6Dc9whUPVUz9N4JT+z02AkTij+8y56aG3O7eLSUtIgo7CKpUNhFEqGwiyRCYRdJhMIukgiFXSQRbOQWyiSPAzg86qJZAE40bABfTbOOrVnHBWhsRdVzbH9nZm1jFRoa9i+dnOw0s47KBuBo1rE167gAja2oRo1Nv8aLJEJhF0lE1WHfUPH5Pc06tmYdF6CxFdWQsVX6N7uINE7Vz+wi0iAKu0giKgk7yWUk/4/khyRfrGIMeUgeIrmXZBfJzorHsolkL8l9oy5rJfkWyQ+yj2PusVfR2NaTPJbddl0kH6hobPNJ7iL5Hsn9JH+UXV7pbeeMqyG3W8P/Zic5HsBfAfwzgKMAdgNYZWbvNXQgOUgeAtBhZpW/AYPkdwGcAbDVzP4+u+w1AH1m9mr2H+UMM3uhSca2HsCZqrfxznYrah+9zTiAFQCeQIW3nTOux9CA262KZ/ZFAD40s4NmdgnAbwEsr2AcTc/M3gbQd9XFywFsyT7fgpEHS8PljK0pmFm3mb2bfT4A4Mo245Xeds64GqKKsM8FcGTU10fRXPu9G4A/kXyH5NqqBzOGOWbWnX3+KYA5VQ5mDMFtvBvpqm3Gm+a2K7L9eSy9QPdli83s2wDuB/B09utqU7KRv8GaqXda0zbejTLGNuOfq/K2K7r9eawqwn4MwPxRX8/LLmsKZnYs+9gLYDuabyvqnis76GYfeysez+eaaRvvsbYZRxPcdlVuf15F2HcDuI3kN0i2APg+gB0VjONLSN6QvXACkjcAWIrm24p6B4DV2eerAbxR4Vi+oFm28c7bZhwV33aVb39uZg3/B+ABjLwi/zcA/1rFGHLGdQuA/83+7a96bAC2YeTXukGMvLaxBsBMADsBfADgfwC0NtHY/hPAXgB7MBKs9orGthgjv6LvAdCV/Xug6tvOGVdDbje9XVYkEXqBTiQRCrtIIhR2kUQo7CKJUNhFEqGwiyRCYRdJxP8DiOECamLE6UYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1WH8z8a6DW9",
        "colab_type": "code",
        "outputId": "3943d0ff-3f7d-4a2b-ffef-babbcbc9ae79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gray.shape\n",
        "new_img = np.expand_dims(gray, axis=2)\n",
        "new_img.shape\n",
        "test_predict = model.predict([[new_img]])\n",
        "test_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awPfm2AW6Rr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}